{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 파이썬 큐에 실시간으로 들어오는 대량의 데이터를 효율적으로 처리하기 위해 몇 가지 방법을 고려할 수 있습니다.\n",
    "\n",
    "이것은 데이터의 특성과 처리해야 할 작업에 따라 다를 수 있으므로, 상황에 따라서 최적의 방법을 선택해야 합니다. 몇 가지 일반적인 방법은 다음과 같습니다:<br>\n",
    "\n",
    "1.**멀티스레딩 또는 멀티프로세싱**: 데이터 처리 작업이 병렬로 수행 가능하다면, 멀티스레딩 또는 멀티프로세싱을 사용하여 여러 작업을 동시에 처리할 수 있습니다.<br>\n",
    "이렇게 하면 처리 속도가 빨라질 수 있습니다. 다만 파이썬의 GIL(Global Interpreter Lock)로 인해 CPU-bound 작업에서는 멀티프로세싱을 고려해야 할 수도 있습니다.<br>\n",
    "\n",
    "2.**비동기 프로그래밍**: 비동기 프로그래밍을 사용하여 I/O 바운드 작업을 효율적으로 처리할 수 있습니다.<br>\n",
    "asyncio나 threading 라이브러리를 사용하여 비동기 작업을 구현할 수 있습니다.<br>\n",
    "\n",
    "3.**큐 버퍼링**: 데이터를 큐에 즉시 넣지 말고, 일정량의 데이터가 모일 때까지 기다렸다가 한 번에 큐에 넣어 처리하는 방식을 고려할 수 있습니다.<br> \n",
    "이로써 큐 조작 횟수를 줄이고 처리 효율을 높일 수 있습니다.<br>\n",
    "\n",
    "4.**분산 시스템**: 대용량 데이터 스트림을 처리해야 하는 경우, 분산 시스템을 고려할 수 있습니다.<br>\n",
    "Apache Kafka, RabbitMQ, Redis 등의 메시지 큐나 스트림 처리 플랫폼을 사용하여 데이터를 분산 및 병렬 처리할 수 있습니다.<br>\n",
    "\n",
    "5.**데이터 전처리**: 실시간으로 들어오는 데이터를 가능한한 빠르게 전처리하고 필요한 정보를 추출하여 최소한의 데이터만을 처리하는 것도 고려할 만합니다.<br>\n",
    "\n",
    "6.**캐싱**: 이전에 처리한 데이터를 캐싱하여 중복 작업을 피하고 처리 속도를 향상시킬 수 있습니다.<br>\n",
    "set() 함수를 이용하여 중복 처리가능.<br>\n",
    "\n",
    "7.**최적화**: 데이터 처리 코드 자체를 최적화하고, 가장 시간이 많이 소요되는 부분을 식별하고 최적화하는 작업도 고려할 필요가 있습니다.<br>\n",
    "\n",
    "8.**큐 시스템 선택**: 데이터가 큐에 들어오는 시스템을 선택할 때 큐 시스템의 성능과 확장성을 고려해야 합니다. 적합한 큐 시스템을 선택하여 대용량 데이터를 효율적으로 처리할 수 있습니다.<br>\n",
    "\n",
    "데이터의 특성과 처리해야 하는 작업에 따라 어떤 방법이 가장 효과적인지는 다를 수 있으므로, 실제 상황에 맞게 적절한 방법을 선택해야 합니다.<br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 내가 만드는 실시간 시세에서는 6번 캐싱 방식을 이용해야 최적화가 가능해 보임.\n",
    "\n",
    "캐싱(Caching)은 컴퓨터 과학과 정보 기술 분야에서 주로 사용되는 개념으로, 이전에 계산한 결과나 데이터를 임시로 저장하여 나중에 같은 데이터나 계산을 다시 수행하지 않고 빠르게 접근할 수 있도록 하는 기술 또는 메커니즘을 가리킵니다.\n",
    "\n",
    "캐싱은 주로 다음과 같은 이점을 제공합니다:\n",
    "\n",
    "1. **성능 향상**: 이전에 계산한 결과나 데이터를 캐시에 저장하면 계산 및 데이터 접근 속도를 향상시킵니다. 캐시에 저장된 데이터는 메모리나 빠른 스토리지에 위치하므로 접근 시간이 줄어듭니다.\n",
    "\n",
    "2. **중복 작업 제거**: 동일한 계산이나 데이터 요청이 여러 번 발생하는 경우 중복 작업을 피하고 시스템 리소스를 절약할 수 있습니다.\n",
    "\n",
    "3. **부하 분산**: 데이터나 계산 결과를 캐시에 저장함으로써 원격 서버 또는 데이터베이스에 대한 부하를 분산시킬 수 있습니다. 이는 서비스의 확장성을 향상시키는 데 도움이 됩니다.\n",
    "\n",
    "4. **응답 시간 감소**: 빠른 데이터 접근은 응답 시간을 단축하고 사용자 경험을 향상시킵니다.\n",
    "\n",
    "주로 사용되는 캐싱의 종류로는 메모리 캐시, 디스크 캐시, 웹 캐싱, 데이터베이스 캐시 등이 있습니다. 예를 들어, 웹 브라우저에서 이미지나 스크립트 파일을 캐싱하여 웹 페이지 로딩 속도를 향상시키거나, 데이터베이스에서 쿼리 결과를 캐시하여 데이터베이스 부하를 감소시키는 것이 일반적인 캐싱의 예시입니다.\n",
    "\n",
    "캐싱은 데이터의 유효성(validity)을 관리하고, 캐시된 데이터를 업데이트하거나 만료된 데이터를 제거하는 메커니즘도 포함합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파이썬 큐에서 중복 데이터를 처리하기 위해 캐싱을 구현할 수 있습니다. 아래는 중복 데이터를 처리하기 위한 간단한 캐싱 코드의 예제입니다:\n",
    "# import queue\n",
    "\n",
    "# # 큐 생성\n",
    "# my_queue = queue.Queue()\n",
    "\n",
    "# # 캐시 생성\n",
    "# data_cache = set()\n",
    "\n",
    "# while True:\n",
    "#     data = my_queue.get()  # 큐에서 데이터 가져옴\n",
    "#     if data not in data_cache:\n",
    "#         data_cache.add(data)\n",
    "#         # 중복되지 않는 데이터 처리 로직을 여기에 추가\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "import queue\n",
    "\n",
    "my_queue = queue.Queue()\n",
    "\n",
    "for _ in range(10):\n",
    "    my_queue.put(3)\n",
    "\n",
    "while not my_queue.empty():\n",
    "    data = my_queue.get()\n",
    "    print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "import queue\n",
    "\n",
    "my_queue = queue.Queue()\n",
    "processed_data = set()  # 이미 처리한 데이터를 저장할 셋(set) 생성\n",
    "\n",
    "for _ in range(10):\n",
    "    my_queue.put(3)\n",
    "\n",
    "while not my_queue.empty():\n",
    "    data = my_queue.get()\n",
    "    \n",
    "    # 이미 처리한 데이터인지 확인\n",
    "    if data not in processed_data:\n",
    "        processed_data.add(data)  # 새로운 데이터를 캐싱에 추가\n",
    "        print(data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 큐에 있는 중복 데이터 처리함에 있어서...\n",
    "\n",
    "중복 데이터를 처리할 때 어떤 방법이 더 빠른지는 상황에 따라 다를 수 있습니다. 중복 데이터를 처리할 때 고려해야 할 요소는 다음과 같습니다:\n",
    "\n",
    "1. 중복 데이터의 빈도: 중복 데이터가 자주 발생하는 경우(10,10, 20, 20), 중복 데이터를 무시하는 것이 더 효율적일 수 있습니다. 중복 데이터를 무시하면 처리 로직이 더 간단하고 빠를 수 있습니다.\n",
    "\n",
    "2. 중복 데이터의 처리 복잡도: 중복 데이터를 처리하기 위한 추가적인 연산이 어려운 경우, 중복 데이터를 캐싱하고 처리하는 것이 빠를 수 있습니다. 중복 데이터를 캐싱하면 중복 처리를 한 번만 하고 나머지 중복 데이터는 무시할 수 있습니다.\n",
    "\n",
    "3. 데이터 크기와 저장 공간: 중복 데이터를 캐싱하면 추가적인 저장 공간이 필요하므로 데이터 크기와 메모리 사용량을 고려해야 합니다.\n",
    "\n",
    "4. 처리 로직의 복잡도: 중복 데이터를 처리하는 로직이 간단한 경우, 중복 데이터를 무시하는 것이 더 간단하고 빠를 수 있습니다. 처리 로직이 복잡한 경우, 중복 데이터를 캐싱하는 것이 중복 처리를 최소화할 수 있습니다.\n",
    "\n",
    "최적의 방법은 데이터의 특성과 처리 로직에 따라 다를 것이며, 성능 테스트를 통해 어떤 방법이 더 효율적인지 확인하는 것이 좋습니다. 중복 데이터 처리가 중요한 경우, 중복 데이터를 캐싱하는 방법을 고려하는 것이 좋습니다.\n",
    "\n",
    "내가 생각해봤을땐 중복 data처리 안하는게 더 최적화가 좋을듯?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
